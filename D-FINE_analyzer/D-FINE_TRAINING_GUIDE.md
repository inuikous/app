# D-FINE å­¦ç¿’å®Ÿè£…ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦
HuggingFace ã® D-FINE (Detection Transformer with Improved Denoising Anchor Boxes) ã‚’ä½¿ç”¨ã—ãŸã‚«ã‚¹ã‚¿ãƒ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’å®Ÿè£…ã«ãŠã‘ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ã¾ã¨ã‚ãŸã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## 1. ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬è¨­å®š

### 1.1 ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
```python
from transformers import AutoImageProcessor, AutoModelForObjectDetection

model_name = "ustc-community/dfine-xlarge-coco"
num_classes = 7  # ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹æ•°

processor = AutoImageProcessor.from_pretrained(model_name)
model = AutoModelForObjectDetection.from_pretrained(
    model_name,
    num_labels=num_classes,  # â˜…é‡è¦: ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹æ•°ã‚’æŒ‡å®š
    ignore_mismatched_sizes=True  # â˜…é‡è¦: ã‚µã‚¤ã‚ºä¸ä¸€è‡´ã‚’è¨±å¯
)
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- `num_labels` ã‚’å¿…ãšæŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯COCOã®91ã‚¯ãƒ©ã‚¹ï¼‰
- `ignore_mismatched_sizes=True` ã§åˆ†é¡ãƒ˜ãƒƒãƒ‰ã®ã‚µã‚¤ã‚ºå¤‰æ›´ã‚’è¨±å¯

---

## 2. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™

### 2.1 COCOå½¢å¼ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
D-FINEã¯å†…éƒ¨çš„ã«COCOå½¢å¼ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ãŒã€**å­¦ç¿’æ™‚ã¯æ‰‹å‹•ã§ãƒ©ãƒ™ãƒ«ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™**ã€‚

```python
# COCO JSONã‹ã‚‰ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èª­ã¿è¾¼ã¿
annotations_list = [ann for ann in annotations if ann['image_id'] == image_id]

# â˜…é‡è¦: æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™å½¢å¼ [cx, cy, w, h] ã«å¤‰æ›
boxes = []
class_labels = []

for ann in annotations_list:
    x, y, w, h = ann['bbox']  # COCOå½¢å¼: [x, y, width, height]
    
    # æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™ã«å¤‰æ›
    cx = (x + w / 2) / img_w  # ä¸­å¿ƒXåº§æ¨™ï¼ˆ0-1ã«æ­£è¦åŒ–ï¼‰
    cy = (y + h / 2) / img_h  # ä¸­å¿ƒYåº§æ¨™ï¼ˆ0-1ã«æ­£è¦åŒ–ï¼‰
    nw = w / img_w            # å¹…ï¼ˆ0-1ã«æ­£è¦åŒ–ï¼‰
    nh = h / img_h            # é«˜ã•ï¼ˆ0-1ã«æ­£è¦åŒ–ï¼‰
    
    boxes.append([cx, cy, nw, nh])
    class_labels.append(ann['category_id'])

# labelsã¨ã—ã¦æ¸¡ã™
labels = {
    'boxes': torch.tensor(boxes, dtype=torch.float32),
    'class_labels': torch.tensor(class_labels, dtype=torch.int64)
}
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- âŒ COCOå½¢å¼ã® `[x, y, width, height]` ã‚’ãã®ã¾ã¾ä½¿ã‚ãªã„
- âœ… **æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™** `[cx, cy, w, h]` ã«å¤‰æ›
- âœ… ã™ã¹ã¦ã®å€¤ã‚’ `[0, 1]` ã®ç¯„å›²ã«æ­£è¦åŒ–

### 2.2 ç”»åƒã®å‰å‡¦ç†
```python
# processorã‚’ä½¿ç”¨ï¼ˆè‡ªå‹•ã§æ­£ã—ã„å½¢å¼ã«å¤‰æ›ï¼‰
inputs = processor(images=image, return_tensors="pt")
pixel_values = inputs['pixel_values']
```

---

## 3. å­¦ç¿’è¨­å®šã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ

### 3.1 ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®å‡çµ/è§£å‡

**âŒ å¤±æ•—ä¾‹: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³å‡çµï¼ˆfreeze_backbone=trueï¼‰**
```python
# å‡ºåŠ›å±¤ã®ã¿å­¦ç¿’
for name, param in model.named_parameters():
    if 'backbone' in name or 'encoder' in name:
        param.requires_grad = False
```
**çµæœ:**
- Val Loss: 1.87
- æ¤œå‡ºç²¾åº¦: ã‚ãšã‹2%
- å•é¡Œ: class_embedã®ãƒã‚¤ã‚¢ã‚¹ãŒè² ã®å€¤ï¼ˆ-1.9å‰å¾Œï¼‰ã«ãªã‚Šã€æ¤œå‡ºã‚¹ã‚³ã‚¢ãŒæ¥µç«¯ã«ä½ä¸‹

**âœ… æˆåŠŸä¾‹: ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³è§£å‡ï¼ˆfreeze_backbone=falseï¼‰**
```python
# å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’
for param in model.parameters():
    param.requires_grad = True
```
**çµæœ:**
- Val Loss: 0.0386ï¼ˆ**48å€æ”¹å–„ï¼**ï¼‰
- ã‚¨ãƒãƒƒã‚¯46ã§é”æˆ
- å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç´„62.5Mï¼‰ã‚’å­¦ç¿’

**çµè«–: D-FINEã§ã¯æœ€åˆã‹ã‚‰å…¨ä½“ã‚’å­¦ç¿’ã™ã‚‹æ–¹ãŒåŠ¹æœçš„**

### 3.2 ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```yaml
training:
  num_epochs: 50
  batch_size: 1          # GPU ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦èª¿æ•´
  learning_rate: 0.0001  # 1e-4ï¼ˆAdamWæ¨å¥¨ï¼‰
  weight_decay: 0.0001
  freeze_backbone: false # â˜…é‡è¦: å¿…ãšfalseã«ã™ã‚‹
```

---

## 4. å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã®å®Ÿè£…

### 4.1 æå¤±è¨ˆç®—
```python
outputs = model(
    pixel_values=pixel_values.to(device),
    labels=labels_batch  # labelsã¯ãƒªã‚¹ãƒˆå½¢å¼
)
loss = outputs.loss  # D-FINEãŒè‡ªå‹•è¨ˆç®—
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- D-FINEã¯å†…éƒ¨ã§è¤‡æ•°ã®æå¤±ï¼ˆåˆ†é¡ã€bboxã€ãƒãƒƒãƒãƒ³ã‚°ãªã©ï¼‰ã‚’è¨ˆç®—
- `outputs.loss` ã‚’ç›´æ¥ä½¿ç”¨ã§ãã‚‹

### 4.2 ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
```python
# ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
if val_loss < best_val_loss:
    best_val_loss = val_loss
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'val_loss': val_loss
    }, 'checkpoints/best_model.pth')
```

---

## 5. æ¨è«–æ™‚ã®æ³¨æ„ç‚¹

### 5.1 ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
```python
# â˜…é‡è¦: num_labelsã‚’æŒ‡å®šã—ã¦ã‹ã‚‰state_dictã‚’ãƒ­ãƒ¼ãƒ‰
model = AutoModelForObjectDetection.from_pretrained(
    model_name,
    num_labels=num_classes,  # å­¦ç¿’æ™‚ã¨åŒã˜ã‚¯ãƒ©ã‚¹æ•°
    ignore_mismatched_sizes=True
)

checkpoint = torch.load(checkpoint_path)
model.load_state_dict(checkpoint['model_state_dict'])
```

**é‡è¦ãƒã‚¤ãƒ³ãƒˆ:**
- æ¨è«–æ™‚ã‚‚ `num_labels` ã‚’å¿…ãšæŒ‡å®š
- æŒ‡å®šã—ãªã„ã¨COCOã®91ã‚¯ãƒ©ã‚¹ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã€RuntimeErrorãŒç™ºç”Ÿ

### 5.2 å¾Œå‡¦ç†
```python
target_sizes = torch.tensor([image.size[::-1]])  # (height, width)
results = processor.post_process_object_detection(
    outputs,
    threshold=0.25,  # ä¿¡é ¼åº¦é–¾å€¤ï¼ˆèª¿æ•´ãŒå¿…è¦ãªå ´åˆã‚ã‚Šï¼‰
    target_sizes=target_sizes
)[0]

# çµæœã®å–å¾—
for score, label, box in zip(results['scores'], results['labels'], results['boxes']):
    score = score.item()
    label = label.item()
    box = [b.item() for b in box]  # [x1, y1, x2, y2]
```

### 5.3 ä¿¡é ¼åº¦é–¾å€¤ã®èª¿æ•´
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.5
- ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³å‡çµæ™‚: 0.25ã§ã‚‚æ¤œå‡ºãŒå›°é›£
- ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³è§£å‡å¾Œ: é©åˆ‡ãªé–¾å€¤ã‚’å®Ÿé¨“çš„ã«æ±ºå®š

---

## 6. ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 6.1 æ¤œå‡ºç²¾åº¦ãŒæ¥µç«¯ã«ä½ã„ï¼ˆ2%ä»¥ä¸‹ï¼‰
**åŸå› :**
- ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ãŒå‡çµã•ã‚Œã¦ã„ã‚‹
- class_embedã®ãƒã‚¤ã‚¢ã‚¹ãŒè² ã®å€¤ã«ãªã£ã¦ã„ã‚‹

**è§£æ±ºç­–:**
```yaml
freeze_backbone: false  # å…¨ä½“ã‚’å­¦ç¿’
```

### 6.2 Val Lossã¯ä½ã„ãŒæ¤œå‡ºã•ã‚Œãªã„
**åŸå› :**
- ä¿¡é ¼åº¦é–¾å€¤ãŒé«˜ã™ãã‚‹
- ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢åˆ†å¸ƒã‚’ç¢ºèª

**è§£æ±ºç­–:**
```python
# ç”Ÿã®logitsã‚’ç¢ºèª
logits = outputs.logits[0]
probs = torch.softmax(logits, dim=-1)
max_probs = probs.max(dim=-1)[0]
print(f"æœ€å¤§ã‚¹ã‚³ã‚¢: {max_probs.max().item()}")
```

### 6.3 RuntimeError: size mismatch
**åŸå› :**
- æ¨è«–æ™‚ã« `num_labels` ã‚’æŒ‡å®šã—ã¦ã„ãªã„

**è§£æ±ºç­–:**
```python
# å¿…ãšæŒ‡å®š
model = AutoModelForObjectDetection.from_pretrained(
    model_name,
    num_labels=7,  # å­¦ç¿’æ™‚ã¨åŒã˜
    ignore_mismatched_sizes=True
)
```

---

## 7. ãƒ‡ãƒ¼ã‚¿é‡ã¨ç²¾åº¦ã®é–¢ä¿‚

### å®Ÿé¨“çµæœ
| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ | Train/Val | Val Loss | æ¤œå‡ºç²¾åº¦ | å‚™è€ƒ |
|------------|-----------|----------|---------|------|
| 100æš (å‡çµ) | 80/20 | 1.7511 | 10% | ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³å‡çµ |
| 1000æš (å‡çµ) | 800/200 | 1.8700 | 2% | ãƒ‡ãƒ¼ã‚¿å¢—åŠ ã§ã‚‚æ”¹å–„ã›ãš |
| 1000æš (è§£å‡) | 800/200 | **0.0386** | è©•ä¾¡ä¸­ | **48å€æ”¹å–„ï¼** |

**çµè«–:**
- ãƒ‡ãƒ¼ã‚¿é‡ã‚’å¢—ã‚„ã™ã ã‘ã§ã¯åŠ¹æœãªã—
- **ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³è§£å‡ãŒæ±ºå®šçš„ã«é‡è¦**

---

## 8. æ¨å¥¨ã™ã‚‹å­¦ç¿’ãƒ•ãƒ­ãƒ¼

```python
# 1. è¨­å®š
config = {
    'model': {
        'name': 'ustc-community/dfine-xlarge-coco',
        'num_classes': 7
    },
    'training': {
        'num_epochs': 50,
        'batch_size': 1,
        'learning_rate': 1e-4,
        'freeze_backbone': False  # â˜…é‡è¦
    }
}

# 2. ãƒ¢ãƒ‡ãƒ«æº–å‚™
model = AutoModelForObjectDetection.from_pretrained(
    config['model']['name'],
    num_labels=config['model']['num_classes'],
    ignore_mismatched_sizes=True
)

# 3. å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å­¦ç¿’å¯èƒ½ã«
for param in model.parameters():
    param.requires_grad = True

# 4. ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=config['training']['learning_rate']
)

# 5. å­¦ç¿’ãƒ«ãƒ¼ãƒ—
for epoch in range(config['training']['num_epochs']):
    # å­¦ç¿’
    model.train()
    for batch in train_dataloader:
        outputs = model(
            pixel_values=batch['pixel_values'].to(device),
            labels=batch['labels']
        )
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
    
    # æ¤œè¨¼
    model.eval()
    # ...
```

---

## 9. ã¾ã¨ã‚

### âœ… å¿…ãšå®Ÿæ–½ã™ã‚‹ã“ã¨
1. `num_labels` ã‚’å­¦ç¿’æ™‚ãƒ»æ¨è«–æ™‚ã¨ã‚‚ã«æŒ‡å®š
2. `freeze_backbone: false` ã§å…¨ä½“ã‚’å­¦ç¿’
3. æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™ `[cx, cy, w, h]` ã‚’ä½¿ç”¨
4. `ignore_mismatched_sizes=True` ã‚’è¨­å®š

### âŒ é¿ã‘ã‚‹ã¹ãã“ã¨
1. ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®å‡çµï¼ˆå°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚ï¼‰
2. COCOå½¢å¼ã®bboxã‚’ãã®ã¾ã¾ä½¿ç”¨
3. æ¨è«–æ™‚ã® `num_labels` æŒ‡å®šå¿˜ã‚Œ

### ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹çµæœ
- Val Loss: 0.03-0.05ç¨‹åº¦ã¾ã§ä½ä¸‹
- é©åˆ‡ãªä¿¡é ¼åº¦é–¾å€¤ã§é«˜ç²¾åº¦ãªæ¤œå‡ºãŒå¯èƒ½
- ã‚¨ãƒãƒƒã‚¯40-50ã§åæŸ

---

## 10. å‚è€ƒæƒ…å ±

- **ãƒ¢ãƒ‡ãƒ«:** [ustc-community/dfine-xlarge-coco](https://huggingface.co/ustc-community/dfine-xlarge-coco)
- **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°:** ç´„62.5M
- **æ¨å¥¨GPU:** 8GBä»¥ä¸Šã®VRAM
- **å­¦ç¿’æ™‚é–“:** ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³è§£å‡æ™‚ã¯ç´„1æ™‚é–“/50ã‚¨ãƒãƒƒã‚¯ï¼ˆGPUä¾å­˜ï¼‰

---

## å¤‰æ›´å±¥æ­´

- 2025-11-08: åˆç‰ˆä½œæˆ
  - ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³å‡çµã®å•é¡Œã‚’ç‰¹å®š
  - ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³è§£å‡ã§Val Loss 48å€æ”¹å–„ã‚’ç¢ºèª
  - æ­£è¦åŒ–ã•ã‚ŒãŸä¸­å¿ƒåº§æ¨™ã®é‡è¦æ€§ã‚’è¿½è¨˜
